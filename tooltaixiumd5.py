import hashlib, random, re
from collections import deque
import requests

# + Th·ªëng k√™ to√†n c·ª•c
total_predictions = 0
correct_count = 0
correct_predictions = {"T√†i": 0, "X·ªâu": 0}

recent_predictions = deque(maxlen=50)
recent_results = deque(maxlen=50)

# + Th·ªëng k√™ theo c·ª•m prefix MD5 (4 k√Ω t·ª± ƒë·∫ßu)
prefix_stats = {}

# Th√™m bi·∫øn to√†n c·ª•c cho thu·∫≠t to√°n ph√¢n t√≠ch chu·ªói
MD5_RESULT_HISTORY_LEN = 3
sequence_patterns = {}

# H·∫±ng s·ªë cho Laplace Smoothing
ALPHA_SMOOTHING = 1
# H·∫±ng s·ªë cho Tr·ªçng s·ªë theo th·ªùi gian (Decay Factor)
DECAY_FACTOR = 0.95
# T·ªïng s·ªë lo·∫°i k·∫øt qu·∫£ c√≥ th·ªÉ (T√†i, X·ªâu)
TOTAL_POSSIBLE_OUTCOMES = 2

def md5_to_number(md5_hash):
    """Chuy·ªÉn ƒë·ªïi hash MD5 th√†nh 3 s·ªë x√∫c x·∫Øc."""
    num = int(md5_hash, 16)
    return [(num >> (8 * i)) % 6 + 1 for i in range(3)]

def sum_to_tx(dice):
    """Chuy·ªÉn t·ªïng x√∫c x·∫Øc th√†nh T√†i ho·∫∑c X·ªâu."""
    return "T√†i" if sum(dice) >= 11 else "X·ªâu"

def determine_result(md5_hash):
    """X√°c ƒë·ªãnh k·∫øt qu·∫£ T√†i/X·ªâu t·ª´ hash MD5."""
    return sum_to_tx(md5_to_number(md5_hash))

def bias_by_streak():
    """Ki·ªÉm tra v√† c·∫£nh b√°o v·ªÅ chu·ªói k·∫øt qu·∫£ li√™n ti·∫øp."""
    if len(recent_results) < 4:
        return None
    last = recent_results[-1]
    streak = 1
    for res in reversed(list(recent_results)[-5:-1]):
        if res == last:
            streak += 1
        else:
            break
    if streak >= 3:
        print(f"‚ö†Ô∏è ƒê√£ c√≥ {streak} l·∫ßn {last} li√™n ti·∫øp. N√™n c√¢n nh·∫Øc ƒë·ª£i phi√™n sau.")
    return None

# ƒê√£ b·ªè h√†m bias_by_winrate() theo y√™u c·∫ßu c·ªßa b·∫°n

def bias_by_prefix(md5_hash):
    """ƒê√°nh gi√° xu h∆∞·ªõng d·ª±a tr√™n ti·ªÅn t·ªë MD5."""
    prefix = md5_hash[:4]
    if prefix in prefix_stats:
        data = prefix_stats[prefix]
        if data["T√†i"] > data["X·ªâu"]:
            print(f"üí° Prefix {prefix} c√≥ xu h∆∞·ªõng T√†i ({data['T√†i']} vs {data['X·ªâu']})")
        elif data["X·ªâu"] > data["T√†i"]:
            print(f"üí° Prefix {prefix} c√≥ xu h∆∞·ªõng X·ªâu ({data['X·ªâu']} vs {data['T√†i']})")
        else:
            print(f"üí° Prefix {prefix} ch∆∞a c√≥ xu h∆∞·ªõng r√µ r√†ng ({data['T√†i']} vs {data['X·ªâu']})")
    else:
        print(f"üí° Prefix {prefix} ch∆∞a t·ª´ng xu·∫•t hi·ªán tr∆∞·ªõc ƒë√≥.")
    return None

# --- C·∫£i ti·∫øn cho c√°c h√†m c·ªët l√µi ---

def calculate_weighted_likelihoods():
    """
    T√≠nh to√°n x√°c su·∫•t (likelihoods) c·ªßa T√†i v√† X·ªâu
    s·ª≠ d·ª•ng Laplace Smoothing v√† Tr·ªçng s·ªë theo th·ªùi gian cho to√†n b·ªô l·ªãch s·ª≠.
    """
    if not recent_results:
        return {"T√†i": 0.5, "X·ªâu": 0.5}

    weighted_counts = {"T√†i": 0.0, "X·ªâu": 0.0}
    total_weighted_sum = 0.0

    # Duy·ªát ng∆∞·ª£c l·ªãch s·ª≠ ƒë·ªÉ g√°n tr·ªçng s·ªë gi·∫£m d·∫ßn
    for i, result in enumerate(reversed(recent_results)):
        weight = DECAY_FACTOR ** i
        weighted_counts[result] += weight
        total_weighted_sum += weight

    # √Åp d·ª•ng Laplace Smoothing
    likelihood_tai = (weighted_counts["T√†i"] + ALPHA_SMOOTHING) / \
                     (total_weighted_sum + ALPHA_SMOOTHING * TOTAL_POSSIBLE_OUTCOMES)
    likelihood_xiu = (weighted_counts["X·ªâu"] + ALPHA_SMOOTHING) / \
                     (total_weighted_sum + ALPHA_SMOOTHING * TOTAL_POSSIBLE_OUTCOMES)

    # Chu·∫©n h√≥a ƒë·ªÉ t·ªïng x√°c su·∫•t l√† 1
    normalized_total = likelihood_tai + likelihood_xiu
    return {
        "T√†i": likelihood_tai / normalized_total,
        "X·ªâu": likelihood_xiu / normalized_total
    }

def predict_by_sequence():
    """
    D·ª± ƒëo√°n d·ª±a tr√™n chu·ªói l·ªãch s·ª≠ g·∫ßn nh·∫•t (N-gram),
    √°p d·ª•ng Laplace Smoothing v√† Tr·ªçng s·ªë theo th·ªùi gian.
    Tr·∫£ v·ªÅ d·ª± ƒëo√°n chu·ªói ho·∫∑c None.
    """
    global sequence_patterns

    sequence_length = MD5_RESULT_HISTORY_LEN

    if len(recent_results) < sequence_length:
        return None

    current_sequence = tuple(list(recent_results)[-sequence_length:])

    if current_sequence in sequence_patterns:
        pattern_data = sequence_patterns[current_sequence]

        smoothed_predictions = {}
        total_smoothed_count = 0.0

        for outcome in ["T√†i", "X·ªâu"]:
            smoothed_predictions[outcome] = pattern_data.get(outcome, 0.0) + ALPHA_SMOOTHING
            total_smoothed_count += smoothed_predictions[outcome]

        if total_smoothed_count > 0:
            tai_prob = smoothed_predictions["T√†i"] / total_smoothed_count
            xiu_prob = smoothed_predictions["X·ªâu"] / total_smoothed_count

            # Ng∆∞·ª°ng tin c·∫≠y c·ªßa m·∫´u chu·ªói
            pattern_confidence_threshold = 0.60

            # ƒê√£ b·ªè ƒëo·∫°n print v√† return theo y√™u c·∫ßu c·ªßa b·∫°n
            if tai_prob >= pattern_confidence_threshold:
                return "T√†i"
            elif xiu_prob >= pattern_confidence_threshold:
                return "X·ªâu"

    return None # Quay v·ªÅ None n·∫øu kh√¥ng c√≥ m·∫´u r√µ r√†ng ho·∫∑c l·ªãch s·ª≠ kh√¥ng ƒë·ªß

def calculate_likelihoods(base_prediction, sequence_prediction):
    """
    T√≠nh to√°n c√°c likelihood t·ª´ c√°c b·∫±ng ch·ª©ng (MD5, Sequence Bias)
    D·ª±a tr√™n c√°c x√°c su·∫•t c∆° b·∫£n ƒë√£ ƒë∆∞·ª£c l√†m m∆∞·ª£t v√† c√≥ tr·ªçng s·ªë.
    """
    likelihoods = {}

    # S·ª≠ d·ª•ng x√°c su·∫•t t·ªïng th·ªÉ ƒë√£ ƒë∆∞·ª£c l√†m m∆∞·ª£t l√†m c∆° s·ªü cho likelihoods
    current_weighted_likelihoods = calculate_weighted_likelihoods()

    md5_bonus_match = 0.10 # TƒÉng ·∫£nh h∆∞·ªüng
    md5_penalty_mismatch = 0.10 # TƒÉng ·∫£nh h∆∞·ªüng

    # Likelihood t·ª´ d·ª± ƒëo√°n MD5 g·ªëc
    if base_prediction == "T√†i":
        likelihood_tai_md5 = current_weighted_likelihoods["T√†i"] + md5_bonus_match
        likelihood_xiu_md5 = current_weighted_likelihoods["X·ªâu"] - md5_penalty_mismatch
    else: # base_prediction == "X·ªâu"
        likelihood_tai_md5 = current_weighted_likelihoods["T√†i"] - md5_penalty_mismatch
        likelihood_xiu_md5 = current_weighted_likelihoods["X·ªâu"] + md5_bonus_match

    likelihoods["MD5_Prediction"] = {
        "T√†i": max(0.01, min(0.99, likelihood_tai_md5)),
        "X·ªâu": max(0.01, min(0.99, likelihood_xiu_md5))
    }

    sequence_bias_impact = 0.05 # TƒÉng ·∫£nh h∆∞·ªüng c·ªßa bias chu·ªói

    if sequence_prediction is not None:
        if sequence_prediction == "T√†i":
            likelihoods["Sequence_Bias"] = {
                "T√†i": current_weighted_likelihoods["T√†i"] + sequence_bias_impact,
                "X·ªâu": current_weighted_likelihoods["X·ªâu"] - sequence_bias_impact
            }
        else: # sequence_prediction == "X·ªâu"
            likelihoods["Sequence_Bias"] = {
                "T√†i": current_weighted_likelihoods["T√†i"] - sequence_bias_impact,
                "X·ªâu": current_weighted_likelihoods["X·ªâu"] + sequence_bias_impact
            }

        likelihoods["Sequence_Bias"]["T√†i"] = max(0.01, min(0.99, likelihoods["Sequence_Bias"]["T√†i"]))
        likelihoods["Sequence_Bias"]["X·ªâu"] = max(0.01, min(0.99, likelihoods["Sequence_Bias"]["X·ªâu"]))

    return likelihoods

def analyze_with_bayesian_inference(base_prediction, sequence_prediction):
    """
    Th·ª±c hi·ªán ph√¢n t√≠ch Bayesian Inference, k·∫øt h·ª£p c√°c b·∫±ng ch·ª©ng.
    Prior ƒë∆∞·ª£c l·∫•y t·ª´ x√°c su·∫•t t·ªïng th·ªÉ c√≥ tr·ªçng s·ªë v√† l√†m m∆∞·ª£t.
    """
    # Prior (x√°c su·∫•t ti√™n nghi·ªám) ƒë·ªông, l·∫•y t·ª´ c√°c x√°c su·∫•t t·ªïng th·ªÉ ƒë√£ ƒë∆∞·ª£c l√†m m∆∞·ª£t v√† c√≥ tr·ªçng s·ªë
    prior_probs = calculate_weighted_likelihoods()
    prior_tai = prior_probs["T√†i"]
    prior_xiu = prior_probs["X·ªâu"]

    # ƒê√£ b·ªè winrate_bias t·ª´ tham s·ªë
    evidence_likelihoods = calculate_likelihoods(base_prediction, sequence_prediction)

    # T√≠nh to√°n x√°c su·∫•t h·∫≠u nghi·ªám (Posterior)
    posterior_tai = prior_tai
    posterior_xiu = prior_xiu

    for likelihood_values in evidence_likelihoods.values():
        posterior_tai *= likelihood_values["T√†i"]
        posterior_xiu *= likelihood_values["X·ªâu"]

    total_posterior = posterior_tai + posterior_xiu
    if total_posterior == 0: # Tr√°nh chia cho 0 n·∫øu t·∫•t c·∫£ likelihoods ƒë·ªÅu r·∫•t nh·ªè
        final_prob_tai = 0.5
        final_prob_xiu = 0.5
    else:
        final_prob_tai = posterior_tai / total_posterior
        final_prob_xiu = posterior_xiu / total_posterior

    bayesian_result = "T√†i" if final_prob_tai >= final_prob_xiu else "X·ªâu"

    print(f"‚ú®X√°c xu·∫•t: {bayesian_result} (T√†i: {final_prob_tai:.2%}, X·ªâu: {final_prob_xiu:.2%})")

# --- End C·∫£i ti·∫øn ---


def predict_smart(md5_hash):
    """Th·ª±c hi·ªán d·ª± ƒëo√°n th√¥ng minh k·∫øt h·ª£p nhi·ªÅu thu·∫≠t to√°n."""
    base_prediction = determine_result(md5_hash)
    print(f"üéØ D·ª± ƒëo√°n: {base_prediction}")

    bias_by_streak()

    # ƒê√£ b·ªè winrate_bias theo y√™u c·∫ßu

    sequence_prediction = predict_by_sequence()
    if sequence_prediction is not None:
        if sequence_prediction == base_prediction:
            print(f"‚úÖ D·ª± ƒëo√°n chu·ªói ({sequence_prediction}) TR√ôNG v·ªõi d·ª± ƒëo√°n MD5 g·ªëc. TƒÉng ƒë·ªô tin c·∫≠y!")
        else:
            print(f"‚ö†Ô∏è D·ª± ƒëo√°n chu·ªói ({sequence_prediction}) KH√ÅC v·ªõi d·ª± ƒëo√°n MD5 g·ªëc ({base_prediction}).")

    # ƒê√£ b·ªè winrate_bias t·ª´ tham s·ªë
    analyze_with_bayesian_inference(base_prediction, sequence_prediction)

    bias_by_prefix(md5_hash)

    # Base_prediction kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi c√°c thu·∫≠t to√°n kh√°c,
    # n√≥ lu√¥n l√† k·∫øt qu·∫£ tr·ª±c ti·∫øp t·ª´ MD5.
    return base_prediction

def update_accuracy(pred, actual, md5_hash=None):
    """C·∫≠p nh·∫≠t c√°c th·ªëng k√™ v√† l·ªãch s·ª≠ k·∫øt qu·∫£."""
    global total_predictions, correct_count, correct_predictions, sequence_patterns

    total_predictions += 1
    correct = (pred == actual)
    if correct:
        correct_count += 1

    accuracy_percentage = (correct_count / total_predictions * 100) if total_predictions > 0 else 0.00

    if correct:
        print(f"‚úÖ ƒê√∫ng ({correct_count}/{total_predictions} - {accuracy_percentage:.2f}%)")
    else:
        print(f"‚ùå Sai ({correct_count}/{total_predictions} - {accuracy_percentage:.2f}%)")
        print("‚ö†Ô∏è D·ª± ƒëo√°n sai, ƒëang t·ªëi ∆∞u.")

    correct_predictions[actual] += 1
    recent_predictions.append(pred)
    recent_results.append(actual)

    # C·∫≠p nh·∫≠t c√°c m·∫´u chu·ªói k·∫øt qu·∫£ (d√πng cho predict_by_sequence)
    sequence_length = MD5_RESULT_HISTORY_LEN
    if len(recent_results) > sequence_length:
        pattern_sequence = tuple(list(recent_results)[-sequence_length-1:-1])
        next_result = actual

        if pattern_sequence not in sequence_patterns:
            sequence_patterns[pattern_sequence] = {"T√†i": 0.0, "X·ªâu": 0.0}
        sequence_patterns[pattern_sequence][next_result] += 1


    if md5_hash:
        prefix = md5_hash[:4]
        if prefix not in prefix_stats:
            prefix_stats[prefix] = {"T√†i": 0, "X·ªâu": 0}
        prefix_stats[prefix][actual] += 1

    total_tx_actual = sum(correct_predictions.values())
    if total_tx_actual > 0:
        tai_percent = (correct_predictions['T√†i'] / total_tx_actual * 100)
        xiu_percent = (correct_predictions['X·ªâu'] / total_tx_actual * 100)
        print(f"üìÄ T√†i: {tai_percent:.2f}%")
        print(f"üíø X·ªâu: {xiu_percent:.2f}%")
    else:
        print("üìÄ T√†i: 0.00%")
        print("üíø X·ªâu: 0.00%")

    print("üî° Nh·∫≠p MD5 ti·∫øp theo ho·∫∑c 'exit' ƒë·ªÉ tho√°t.")

def parse_actual_from_code(s):
    """Ph√¢n t√≠ch k·∫øt qu·∫£ T√†i/X·ªâu t·ª´ chu·ªói x√∫c x·∫Øc (v√≠ d·ª•: 3-4-5)."""
    m = re.search(r'(\d+)-(\d+)-(\d+)', s)
    if m:
        total = sum(map(int, m.groups()))
        return "T√†i" if total >= 11 else "X·ªâu"
    return None

def parse_initial_history(s):
    """Ph√¢n t√≠ch l·ªãch s·ª≠ T√†i/X·ªâu ban ƒë·∫ßu t·ª´ chu·ªói a-b."""
    m = re.fullmatch(r'(\d+)-(\d+)', s)
    if m:
        tai = int(m.group(1))
        xiu = int(m.group(2))
        return tai, xiu
    return None, None

def main():
    """H√†m ch√≠nh c·ªßa ch∆∞∆°ng tr√¨nh."""
    trying = 0

    print("‚ö°Ô∏è Tool D·ª± ƒêo√°n T√†i X·ªâu MD5 AI ‚ö°")
    print("Code made by BaoAn")
    print("üî•Thua t·ª± ch·ªãu")
    print("‚ùïÔ∏èL∆∞u √Ω k·∫øt qu·∫£ nh·∫≠n ƒë∆∞·ª£c ƒë·ªÅu l√† s·ª± t√≠nh to√°n")
    print("üîé Nh·∫≠p l·ªãch s·ª≠ t·ªïng s·ªë phi√™n T√†i - X·ªâu ƒë·ªÉ kh·ªüi t·∫°o ph·∫ßn trƒÉm.")
    while True:
        history_input = input("‚å®Ô∏è Nh·∫≠p l·ªãch s·ª≠ d·∫°ng a-b (T√†i-X·ªâu), v√≠ d·ª• 12-8, no ƒë·ªÉ b·ªè qua ").strip()
        tai, xiu = parse_initial_history(history_input)
        if tai is not None and xiu is not None:
            total_history = tai + xiu
            if total_history == 0:
                print("‚ùóÔ∏è T·ªïng s·ªë phi√™n ph·∫£i l·ªõn h∆°n 0.")
                continue
            print(f"üìà L·ªãch s·ª≠ kh·ªüi t·∫°o: T√†i = {tai} ({tai/total_history*100:.2f}%), X·ªâu = {xiu} ({xiu/total_history*100:.2f}%)")

            global correct_predictions
            correct_predictions["T√†i"] = tai
            correct_predictions["X·ªâu"] = xiu

            break
        elif history_input.lower() == "no":
            print("üö™ B·∫°n ƒë√£ ch·ªçn kh√¥ng nh·∫≠p l·ªãch s·ª≠. Tho√°t kh·ªüi t·∫°o.")
            break
        else:
            print("‚ùóÔ∏è ƒê·ªãnh d·∫°ng kh√¥ng ƒë√∫ng, vui l√≤ng nh·∫≠p l·∫°i theo d·∫°ng a-b ho·∫∑c g√µ 'no' ƒë·ªÉ tho√°t.")

    print("‚å®Ô∏è Nh·∫≠p m√£ MD5 ho·∫∑c k·∫øt qu·∫£ a-b-c (vd: 3-4-5) ƒë·ªÉ d·ª± ƒëo√°n v√† c·∫≠p nh·∫≠t.")
    while True:
        md5_hash = input("üî† Nh·∫≠p m√£ MD5: ").strip()
        if md5_hash.lower() == "exit":
            print("üëã T·∫°m bi·ªát!")
            break
        if md5_hash.upper() == "T":
            print("‚è≥ ƒêang chuy·ªÉn sang ch·∫ø ƒë·ªô th∆∞·ªùng...")
            while True:
                try:
                    # Vi·ªác t·∫£i v√† ch·∫°y code t·ª´ b√™n ngo√†i c√≥ th·ªÉ g√¢y r·ªßi ro b·∫£o m·∫≠t
                    # C·∫ßn c·∫©n tr·ªçng khi s·ª≠ d·ª•ng exec v·ªõi code kh√¥ng ƒë√°ng tin c·∫≠y.
                    md5_code = requests.get("https://raw.githubusercontent.com/baoandepzai/Tool-tai-xiu/refs/heads/main/tooltaixiu.py", timeout = 5).text
                    exec(md5_code, globals())
                    main()
                    break
                except requests.exceptions.RequestException:
                    if trying == 0:
                        print("‚ùå L·ªói k·∫øt n·ªëi m·∫°ng. Kh√¥ng th·ªÉ t·∫£i ch·∫ø ƒë·ªô th∆∞·ªùng.")
                        trying += 1
                except Exception as e:
                    if trying ==0:
                        print("‚ùå L·ªói kh√°c khi t·∫£i ch·∫ø ƒë·ªô MD5:", e)
                        trying += 1
            continue

        if len(md5_hash) != 32 or not re.fullmatch(r'[0-9a-fA-F]{32}', md5_hash):
            print("‚ùóÔ∏è M√£ MD5 kh√¥ng h·ª£p l·ªá.")
            continue

        pred = predict_smart(md5_hash)

        actual_input = input("üåü K·∫øt qu·∫£ th·ª±c t·∫ø (T√†i/X·ªâu ho·∫∑c a-b-c): ").strip().capitalize()
        if "-" in actual_input:
            parsed = parse_actual_from_code(actual_input)
            if parsed:
                update_accuracy(pred, parsed, md5_hash)
            else:
                print("‚ùóÔ∏è Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c k·∫øt qu·∫£.")
        elif actual_input in ["T√†i", "X·ªâu"]:
            update_accuracy(pred, actual_input, md5_hash)
        else:
            print("‚ùóÔ∏è K·∫øt qu·∫£ kh√¥ng h·ª£p l·ªá.")

if __name__ == "__main__":
    main()
